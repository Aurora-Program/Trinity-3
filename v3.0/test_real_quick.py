"""Test rÃ¡pido con embeddings reales - versiÃ³n simplificada"""

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

print("ğŸ”„ Importando sentence-transformers...")
from sentence_transformers import SentenceTransformer

print("âœ… ImportaciÃ³n exitosa")
print("ğŸ”„ Cargando modelo MiniLM-L6-v2 (puede tardar ~1 min en primera ejecuciÃ³n)...")

model = SentenceTransformer('all-MiniLM-L6-v2')

print("âœ… Modelo cargado")
print("\n" + "="*70)
print(" TEST PRESERVACIÃ“N SEMÃNTICA - EMBEDDINGS REALES")
print("="*70)

# Frases del whitepaper
frases = [
    "El gato duerme en el sofÃ¡",       # 0
    "Un felino descansa sobre el sillÃ³n",  # 1 (similar a 0)
    "El perro corre en el parque",     # 2
    "Un can trota por el jardÃ­n"       # 3 (similar a 2)
]

print("\nğŸ“ Frases:")
for i, f in enumerate(frases):
    print(f"  [{i}] {f}")

print("\nğŸ§  Generando embeddings...")
embeddings = model.encode(frases, show_progress_bar=False)
print(f"âœ… Shape: {embeddings.shape}")

# Cosine similarity baseline
def cosine_sim(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

print("\nğŸ“Š Similitudes baseline (Coseno):")
sim_01 = cosine_sim(embeddings[0], embeddings[1])
sim_23 = cosine_sim(embeddings[2], embeddings[3])
sim_02 = cosine_sim(embeddings[0], embeddings[2])
sim_13 = cosine_sim(embeddings[1], embeddings[3])

print(f"  [0â†”1] gato/felino:    {sim_01:.4f} âœ… (esperado: alto)")
print(f"  [2â†”3] perro/can:      {sim_23:.4f} âœ… (esperado: alto)")
print(f"  [0â†”2] gato/perro:     {sim_02:.4f} (esperado: bajo)")
print(f"  [1â†”3] felino/can:     {sim_13:.4f} (esperado: bajo)")

avg_similar = (sim_01 + sim_23) / 2
avg_different = (sim_02 + sim_13) / 2

print(f"\n  Avg similar:    {avg_similar:.4f}")
print(f"  Avg diferente:  {avg_different:.4f}")
print(f"  SeparaciÃ³n:     {avg_similar - avg_different:.4f}")

# FFE Encoding con solo 4 samples (PCA a 3 dims para simplificar)
print("\nğŸ”„ FFE Encoding (PCA a 9 dims para 4 samples)...")

scaler = StandardScaler()
scaled = scaler.fit_transform(embeddings)

pca = PCA(n_components=9)  # MÃ¡ximo 4-1=3 realmente Ãºtiles
reduced = pca.fit_transform(scaled)

print(f"  Varianza preservada: {pca.explained_variance_ratio_.sum()*100:.1f}%")

# Quantizar
mean = reduced.mean()
std = reduced.std()
thresh_low = mean - 0.5 * std
thresh_high = mean + 0.5 * std

tensors = []
for row in reduced:
    tensor = []
    for val in row:
        if val < thresh_low:
            tensor.append(-1)
        elif val > thresh_high:
            tensor.append(1)
        else:
            tensor.append(0)
    tensors.append(tensor)

print("\nğŸ“Š Tensores FFE:")
for i, t in enumerate(tensors):
    nulls = t.count(-1)
    print(f"  [{i}] Nulls: {nulls}/9 ({nulls/9*100:.0f}%)")

# Distancia triÃ¡dica
def triadic_dist(a, b):
    valid = [(x, y) for x, y in zip(a, b) if x != -1 and y != -1]
    if not valid:
        return 0.0
    matches = sum(1 for x, y in valid if x == y)
    return matches / len(valid)

print("\nğŸ“Š Similitudes FFE (TriÃ¡dico):")
sim_01_ffe = triadic_dist(tensors[0], tensors[1])
sim_23_ffe = triadic_dist(tensors[2], tensors[3])
sim_02_ffe = triadic_dist(tensors[0], tensors[2])
sim_13_ffe = triadic_dist(tensors[1], tensors[3])

print(f"  [0â†”1] gato/felino:    {sim_01_ffe:.4f}")
print(f"  [2â†”3] perro/can:      {sim_23_ffe:.4f}")
print(f"  [0â†”2] gato/perro:     {sim_02_ffe:.4f}")
print(f"  [1â†”3] felino/can:     {sim_13_ffe:.4f}")

avg_similar_ffe = (sim_01_ffe + sim_23_ffe) / 2
avg_different_ffe = (sim_02_ffe + sim_13_ffe) / 2

print(f"\n  Avg similar:    {avg_similar_ffe:.4f}")
print(f"  Avg diferente:  {avg_different_ffe:.4f}")
print(f"  SeparaciÃ³n:     {avg_similar_ffe - avg_different_ffe:.4f}")

# Veredicto
print("\n" + "="*70)
print("VEREDICTO")
print("="*70)

test1 = avg_similar_ffe > avg_different_ffe
test2 = (avg_similar_ffe - avg_different_ffe) > 0.05

print(f"\nâœ… Test 1 (Orden): {avg_similar_ffe:.4f} > {avg_different_ffe:.4f} â†’ {'âœ… PASS' if test1 else 'âŒ FAIL'}")
print(f"âœ… Test 2 (Sep):   {avg_similar_ffe - avg_different_ffe:.4f} > 0.05 â†’ {'âœ… PASS' if test2 else 'âŒ FAIL'}")

if test1 and test2:
    print("\nğŸ‰ PRESERVACIÃ“N SEMÃNTICA EXITOSA CON EMBEDDINGS REALES")
    print("âœ¨ Aurora puede operar sobre significado REAL de sentence-transformers")
else:
    print("\nâš ï¸  PreservaciÃ³n parcial - ajustar parÃ¡metros")

print("\n" + "="*70)
