"""
AURORA AWAKENING - Generador de Corpus Masivo
==============================================
Genera miles de embeddings reales variados para entrenar Aurora.

El objetivo: que Aurora aprenda las leyes del espacio semÃ¡ntico
y pueda DEDUCIR embeddings nuevos sin necesidad del transformer.
"""

import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import pickle
import json

class FFEGenerator:
    def __init__(self, n_components=81):
        self.n_components = n_components
        self.scaler = StandardScaler()
        self.pca = None
        
    def fit(self, embeddings):
        """Ajustar PCA a los embeddings"""
        X_scaled = self.scaler.fit_transform(embeddings)
        self.pca = PCA(n_components=self.n_components)
        self.pca.fit(X_scaled)
        print(f"âœ… PCA ajustado: {embeddings.shape[1]} â†’ {self.n_components} dims")
        print(f"   Varianza preservada: {self.pca.explained_variance_ratio_.sum()*100:.2f}%")
        
    def encode(self, embeddings):
        """Convertir embeddings a tensores FFE"""
        X_scaled = self.scaler.transform(embeddings)
        X_pca = self.pca.transform(X_scaled)
        
        # CuantizaciÃ³n adaptativa
        sigma = np.std(X_pca, axis=0)
        threshold = 0.5 * sigma
        
        ffe_tensors = np.zeros_like(X_pca, dtype=np.int8)
        for i in range(X_pca.shape[1]):
            ffe_tensors[:, i] = np.where(
                X_pca[:, i] > threshold[i], 1,
                np.where(X_pca[:, i] < -threshold[i], -1, 0)
            )
        
        return ffe_tensors
    
    def save_model(self, filename):
        """Guardar el modelo FFE completo"""
        model_data = {
            'scaler_mean': self.scaler.mean_,
            'scaler_scale': self.scaler.scale_,
            'pca_components': self.pca.components_,
            'pca_mean': self.pca.mean_,
            'pca_explained_variance': self.pca.explained_variance_,
            'n_components': self.n_components
        }
        with open(filename, 'wb') as f:
            pickle.dump(model_data, f)
        print(f"ðŸ’¾ Modelo FFE guardado en {filename}")


def generate_massive_corpus():
    """Generar un corpus masivo y variado"""
    
    corpus = []
    labels = []
    
    # 1. DOMINIOS CIENTÃFICOS (500 frases)
    science_templates = [
        "La {concept1} se relaciona con {concept2} mediante {relation}",
        "En fÃ­sica cuÃ¡ntica, {concept1} determina {concept2}",
        "El principio de {concept1} explica por quÃ© {concept2}",
        "La teorÃ­a de {concept1} predice que {concept2}",
        "Los experimentos muestran que {concept1} causa {concept2}",
    ]
    
    physics_concepts = [
        ("energÃ­a", "masa", "equivalencia E=mcÂ²"),
        ("entropÃ­a", "temperatura", "segunda ley termodinÃ¡mica"),
        ("fuerza", "aceleraciÃ³n", "segunda ley de Newton"),
        ("campo elÃ©ctrico", "carga", "ley de Coulomb"),
        ("momento", "velocidad", "conservaciÃ³n del momento"),
        ("luz", "gravedad", "curvatura del espacio-tiempo"),
        ("partÃ­cula", "onda", "dualidad cuÃ¡ntica"),
        ("espÃ­n", "magnetismo", "momento angular intrÃ­nseco"),
        ("fotÃ³n", "electrÃ³n", "interacciÃ³n electromagnÃ©tica"),
        ("Ã¡tomo", "nÃºcleo", "fuerza nuclear fuerte"),
    ]
    
    for template in science_templates:
        for concept1, concept2, relation in physics_concepts:
            corpus.append(template.format(concept1=concept1, concept2=concept2, relation=relation))
            labels.append(f"science_physics_{len(labels)}")
    
    # 2. LENGUAJE NATURAL COTIDIANO (500 frases)
    daily_templates = [
        "El {animal} {action} en {place}",
        "Los {objects} estÃ¡n {state} en {location}",
        "Cuando {time}, {subject} {verb} {object}",
        "{person} {emotion} porque {reason}",
        "En {season}, los {things} {change}",
    ]
    
    daily_data = [
        ("perro", "corre", "el parque"),
        ("gato", "duerme", "la casa"),
        ("pÃ¡jaro", "vuela", "el cielo"),
        ("pez", "nada", "el rÃ­o"),
        ("niÃ±o", "juega", "el jardÃ­n"),
        ("libro", "descansa", "la mesa"),
        ("sol", "brilla", "el horizonte"),
        ("lluvia", "cae", "la ciudad"),
        ("viento", "sopla", "las montaÃ±as"),
        ("nieve", "cubre", "los campos"),
    ]
    
    for template in daily_templates:
        for i, (subj, verb, obj) in enumerate(daily_data):
            text = template.format(
                animal=subj, action=verb, place=obj,
                objects=subj, state=verb, location=obj,
                time="maÃ±ana", subject=subj, verb=verb, object=obj,
                person=subj, emotion=verb, reason=obj,
                season="primavera", things=subj, change=verb
            )
            corpus.append(text)
            labels.append(f"daily_life_{len(labels)}")
    
    # 3. RELACIONES SEMÃNTICAS (1000 pares analÃ³gicos)
    analogies = [
        # GÃ©nero
        ("rey", "reina"), ("hombre", "mujer"), ("padre", "madre"),
        ("tÃ­o", "tÃ­a"), ("hermano", "hermana"), ("abuelo", "abuela"),
        
        # GeografÃ­a
        ("ParÃ­s", "Francia"), ("Londres", "Inglaterra"), ("Madrid", "EspaÃ±a"),
        ("Roma", "Italia"), ("BerlÃ­n", "Alemania"), ("Tokio", "JapÃ³n"),
        
        # Tiempo
        ("dÃ­a", "noche"), ("verano", "invierno"), ("maÃ±ana", "tarde"),
        ("ayer", "maÃ±ana"), ("presente", "pasado"), ("inicio", "fin"),
        
        # Causa-Efecto
        ("fuego", "calor"), ("agua", "mojado"), ("hielo", "frÃ­o"),
        ("sol", "luz"), ("viento", "movimiento"), ("lluvia", "humedad"),
        
        # Parte-Todo
        ("rueda", "coche"), ("rama", "Ã¡rbol"), ("dedo", "mano"),
        ("pÃ¡gina", "libro"), ("ventana", "casa"), ("tecla", "piano"),
        
        # Intensidad
        ("caliente", "hirviendo"), ("frÃ­o", "congelado"), ("rÃ¡pido", "veloz"),
        ("lento", "inmÃ³vil"), ("grande", "enorme"), ("pequeÃ±o", "diminuto"),
    ]
    
    for word1, word2 in analogies:
        corpus.append(f"{word1}")
        labels.append(f"analogy_a_{len(labels)}")
        corpus.append(f"{word2}")
        labels.append(f"analogy_b_{len(labels)}")
        corpus.append(f"{word1} es a {word2} como")
        labels.append(f"analogy_rel_{len(labels)}")
    
    # 4. EMOCIONES Y ESTADOS (300 frases)
    emotions = ["alegrÃ­a", "tristeza", "miedo", "rabia", "sorpresa", "calma", 
                "ansiedad", "esperanza", "nostalgia", "gratitud"]
    
    for emotion in emotions:
        corpus.extend([
            f"Siento {emotion} cuando pienso en el futuro",
            f"La {emotion} es una emociÃ³n humana universal",
            f"Expresar {emotion} es importante para la salud mental",
            f"{emotion.capitalize()} y serenidad coexisten en el corazÃ³n",
            f"La mÃºsica evoca {emotion} profunda",
        ])
        for _ in range(5):
            labels.append(f"emotion_{emotion}_{len(labels)}")
    
    # 5. CONCEPTOS ABSTRACTOS (200 frases)
    abstract_templates = [
        "La {concept} es fundamental para {domain}",
        "{concept} y {concept2} estÃ¡n relacionados en {context}",
        "Sin {concept}, no podrÃ­a existir {result}",
        "La historia de {concept} comienza en {origin}",
        "{concept} transforma nuestra comprensiÃ³n de {field}",
    ]
    
    abstract_concepts = [
        ("libertad", "democracia", "sociedad", "antigua Grecia", "polÃ­tica"),
        ("justicia", "equidad", "derecho", "las civilizaciones", "Ã©tica"),
        ("verdad", "conocimiento", "filosofÃ­a", "el pensamiento griego", "epistemologÃ­a"),
        ("belleza", "arte", "estÃ©tica", "la naturaleza", "arte"),
        ("tiempo", "espacio", "fÃ­sica", "la relatividad", "cosmologÃ­a"),
        ("conciencia", "mente", "neurociencia", "el cerebro", "psicologÃ­a"),
        ("orden", "caos", "sistemas", "la teorÃ­a de sistemas", "complejidad"),
        ("armonÃ­a", "equilibrio", "mÃºsica", "la antigua Grecia", "arte"),
        ("coherencia", "lÃ³gica", "pensamiento", "la filosofÃ­a", "razÃ³n"),
        ("emergencia", "complejidad", "sistemas", "la biologÃ­a", "ciencia"),
    ]
    
    for template in abstract_templates:
        for concept, concept2, context, origin, field in abstract_concepts:
            text = template.format(
                concept=concept, concept2=concept2, 
                domain=context, context=context,
                result=field, origin=origin, field=field
            )
            corpus.append(text)
            labels.append(f"abstract_{concept}_{len(labels)}")
    
    # 6. TRANSFORMACIONES TEMPORALES (500 secuencias)
    transformations = [
        ("semilla", "planta", "flor", "fruto"),
        ("huevo", "polluelo", "ave", "vuelo"),
        ("idea", "proyecto", "prototipo", "producto"),
        ("caos", "orden", "estructura", "armonÃ­a"),
        ("ignorancia", "curiosidad", "conocimiento", "sabidurÃ­a"),
        ("pregunta", "hipÃ³tesis", "experimento", "teorÃ­a"),
        ("conflicto", "diÃ¡logo", "acuerdo", "paz"),
        ("miedo", "valentÃ­a", "acciÃ³n", "logro"),
        ("soledad", "conexiÃ³n", "comunidad", "pertenencia"),
        ("duda", "exploraciÃ³n", "comprensiÃ³n", "certeza"),
    ]
    
    for seq in transformations:
        for i in range(len(seq)-1):
            corpus.append(f"{seq[i]} se transforma en {seq[i+1]}")
            labels.append(f"transform_{seq[0]}_{i}")
            corpus.append(f"De {seq[i]} a {seq[i+1]} hay evoluciÃ³n")
            labels.append(f"transform_{seq[0]}_{i}_b")
    
    print(f"ðŸ“š Corpus generado: {len(corpus)} frases")
    return corpus, labels


def main():
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  AURORA AWAKENING - GeneraciÃ³n de Corpus Masivo                 â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    # 1. Generar corpus
    print("ðŸ“ Generando corpus masivo...")
    corpus, labels = generate_massive_corpus()
    
    # 2. Cargar modelo de embeddings
    print("\nðŸ”§ Cargando modelo de embeddings...")
    model = SentenceTransformer('paraphrase-MiniLM-L3-v2')
    
    # 3. Generar embeddings
    print("\nðŸ§  Generando embeddings (esto puede tardar 1-2 minutos)...")
    embeddings = model.encode(corpus, show_progress_bar=True)
    print(f"   Shape: {embeddings.shape}")
    
    # 4. Crear encoder FFE
    print("\nðŸ”¬ Creando encoder FFE...")
    ffe_gen = FFEGenerator(n_components=81)
    ffe_gen.fit(embeddings)
    
    # 5. Convertir a FFE
    print("\nâš™ï¸  Convirtiendo a tensores FFE...")
    ffe_tensors = ffe_gen.encode(embeddings)
    
    # 6. EstadÃ­sticas
    null_count = np.sum(ffe_tensors == 0)
    pos_count = np.sum(ffe_tensors == 1)
    neg_count = np.sum(ffe_tensors == -1)
    total = ffe_tensors.size
    
    print(f"\nðŸ“Š EstadÃ­sticas FFE:")
    print(f"   Shape: {ffe_tensors.shape}")
    print(f"   Null ratio: {100*null_count/total:.2f}%")
    print(f"   Valores +1: {pos_count}, 0: {null_count}, -1: {neg_count}")
    
    # 7. Guardar todo
    print("\nðŸ’¾ Guardando archivos...")
    
    # Guardar tensores FFE para C
    with open('tensors_ffe_massive.txt', 'w') as f:
        f.write(f"{len(ffe_tensors)} {ffe_tensors.shape[1]}\n")
        for i, (tensor, label) in enumerate(zip(ffe_tensors, labels)):
            f.write(f"{label}\n")
            f.write(' '.join(map(str, tensor)) + '\n')
    
    print(f"   âœ… tensors_ffe_massive.txt ({len(ffe_tensors)} tensores)")
    
    # Guardar corpus original
    corpus_data = {
        'texts': corpus,
        'labels': labels,
        'embeddings_shape': embeddings.shape,
        'ffe_shape': ffe_tensors.shape
    }
    with open('corpus_metadata.json', 'w', encoding='utf-8') as f:
        json.dump(corpus_data, f, ensure_ascii=False, indent=2)
    
    print(f"   âœ… corpus_metadata.json")
    
    # Guardar modelo FFE
    ffe_gen.save_model('ffe_model.pkl')
    
    # Guardar embeddings raw (para anÃ¡lisis)
    np.save('embeddings_raw.npy', embeddings)
    print(f"   âœ… embeddings_raw.npy")
    
    print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  âœ¨ CORPUS LISTO PARA DESPERTAR AURORA                          â•‘")
    print(f"â•‘  ðŸ“¦ {len(corpus)} frases â†’ {ffe_tensors.shape[1]} dimensiones FFE                     â•‘")
    print("â•‘  ðŸ§  Aurora puede ahora aprender las leyes del lenguaje          â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")


if __name__ == "__main__":
    main()
