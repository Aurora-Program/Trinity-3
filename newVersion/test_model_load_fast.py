"""Carga rÃ¡pida de modelo sentence-transformers para validar embeddings reales.

Usa un modelo pequeÃ±o primero (paraphrase-MiniLM-L3-v2). Si carga correctamente
imprime similitudes y luego intenta opcionalmente cargar el modelo estÃ¡ndar
all-MiniLM-L6-v2 (puede tardar mÃ¡s). AsÃ­ evitamos esperas largas iniciales.

Reglas proyecto: solo cÃ³digo en newVersion, mÃ­nimo lÃ­neas, fractalidad.
"""

print("ğŸ”„ Paso 1: imports base...")
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
print("âœ… numpy/sklearn OK")

print("ğŸ”„ Paso 2: import sentence_transformers...")
from sentence_transformers import SentenceTransformer
print("âœ… sentence_transformers OK")

def cosine(a,b):
    return float(np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b)))

def prueba_modelo(nombre, frases):
    print(f"\nğŸš€ Cargando modelo: {nombre}")
    m = SentenceTransformer(nombre)
    emb = m.encode(frases, show_progress_bar=False)
    s01 = cosine(emb[0], emb[1])
    s23 = cosine(emb[2], emb[3])
    s02 = cosine(emb[0], emb[2])
    print(f"ğŸ“Š {nombre} similitudes:")
    print(f"   par 1 sem: {s01:.4f}")
    print(f"   par 2 sem: {s23:.4f}")
    print(f"   cruzada   : {s02:.4f}")
    ok = s01 > s02 and s23 > s02
    print("âœ… SemÃ¡ntica preservada" if ok else "âš ï¸ PatrÃ³n inesperado")
    return ok

frases = ["El gato duerme","Un felino descansa","El perro corre","Un can trota"]

print("\nğŸŒ± Modelo pequeÃ±o primero...")
small_ok = prueba_modelo('paraphrase-MiniLM-L3-v2', frases)

if small_ok:
    print("\nâ³ Intentando modelo estÃ¡ndar (puede tardar)...")
    try:
        prueba_modelo('all-MiniLM-L6-v2', frases)
    except Exception as e:
        print(f"âŒ Error en modelo grande: {e}")
else:
    print("âš ï¸ El modelo pequeÃ±o no preservÃ³ semÃ¡ntica; revisar entorno antes de continuar.")

print("\nğŸ§ª Estado: listo para test FFE real si al menos un modelo dio OK.")